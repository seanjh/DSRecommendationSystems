{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from pyspark import SparkContext, SQLContext\n",
    "sc = SparkContext(\"local\", \"test\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"./data//ratings-train.dat/\"\n",
    "VALIDATION_FILE = \"./data//ratings-validation.dat/\"\n",
    "TEST_FILE = \"./data/ratings-test.dat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    return (\n",
    "        data\n",
    "        .map(lambda l: l.split('::'))\n",
    "        .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "ratings_train_text = sc.textFile(TRAIN_FILE)\n",
    "ratings_train = prepare_data(ratings_train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_validation_text = sc.textFile(VALIDATION_FILE)\n",
    "ratings_validation = prepare_data(ratings_validation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_test_text = sc.textFile(TEST_FILE)\n",
    "ratings_test = prepare_data(ratings_validation_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the general mean u for all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_mean = ratings_train.map(lambda r: (r[2])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5436346666666556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### calculate item-specific bias, according to the paper we referenced, for each item i, its bias is equal to the summation of difference between all ratings of to the same item and global mean and then the result is divided by the sum of a regulation parameter and the quantity of the ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert training data to dataframe with attribute\n",
    "df = sqlContext.createDataFrame(ratings_train, ['userId', 'movieId', 'ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sort the data by movie\n",
    "df_orderByMovie = df.orderBy(df.movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group the movie and count each movie\n",
    "movie_count = df_orderByMovie.groupBy(df_orderByMovie.movieId).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate the sum of the ratings of each movie\n",
    "sum_byMovie = df_orderByMovie.groupBy(['movieId']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop some unrelated column\n",
    "drop_column1 = sum_byMovie.drop(sum_byMovie[1])\n",
    "final_drop = drop_column1.drop(drop_column1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join the sum of count and sum of rating for each movie\n",
    "movie_sorted = movie_count.join(final_drop, \"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sorted the dataset by each movie\n",
    "new_movie_sorted = movie_sorted.orderBy(movie_sorted.movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate item specific bias\n",
    "item_bias = new_movie_sorted.map(lambda r: [r[0], (r[2] - r[1]*global_mean)/(25+r[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_item_bias = sqlContext.createDataFrame(item_bias, ['movieId', 'item_bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caculate the user-specific bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#order the training set by user\n",
    "df_orderByUser = df.orderBy(df.userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#join the item bias dataset to with the same movieId\n",
    "contain_itemBias = df_orderByUser.join(new_item_bias, \"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sorted the dataset by user\n",
    "sorted_byUser = contain_itemBias.orderBy(['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the numerical part of item specific bais\n",
    "subtraction = sorted_byUser.map(lambda r: [r[1], r[2] - global_mean - r[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias_part1 = sqlContext.createDataFrame(subtraction, ['userId', 'subtraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_byUser = user_bias_part1.groupBy(['userId']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count the user \n",
    "sum_UserCollect = user_bias_part1.groupBy(['userId']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#order the data set by user\n",
    "ordered_sum_UserCollect = sum_UserCollect.orderBy(sum_UserCollect.userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_column2 = sum_byUser.drop(sum_byUser[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_drop2 = drop_column2.orderBy(drop_column2.userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias_table = final_drop2.join(ordered_sum_UserCollect, 'userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_userBiaTable = user_bias_table.orderBy(user_bias_table.userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias = ordered_userBiaTable.map(lambda r: [r[0], r[1]/(10+r[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_specific_bias = sqlContext.createDataFrame(user_bias, ['userId', 'user_bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge1 = df_orderByUser.join(user_specific_bias, 'userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge2 = merge1.join(new_item_bias, 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_ratings_train = merge2.map(lambda r: [r[0], r[1], r[2] - r[3] - r[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = sqlContext.createDataFrame(new_ratings_train, ['movieId', 'userId', 'new_ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_new_ratings_train = temp.orderBy(temp.userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=231, userId=1, new_ratings=4.500706981668868),\n",
       " Row(movieId=466, userId=1, new_ratings=4.486594220539655),\n",
       " Row(movieId=480, userId=1, new_ratings=3.6659681159289264),\n",
       " Row(movieId=292, userId=1, new_ratings=3.9400823655233252),\n",
       " Row(movieId=316, userId=1, new_ratings=4.070220460584749),\n",
       " Row(movieId=520, userId=1, new_ratings=4.450044040828783),\n",
       " Row(movieId=122, userId=1, new_ratings=4.51965651167074),\n",
       " Row(movieId=329, userId=1, new_ratings=4.043341642853775),\n",
       " Row(movieId=539, userId=1, new_ratings=3.781670437982751),\n",
       " Row(movieId=355, userId=1, new_ratings=4.792371118737552)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_new_ratings_train.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now, we perform the same procedure as task1\n",
    "#first, we sort the data by timestamp. \n",
    "new_ratings_byTime = final_new_ratings_train.join(df, ['userId', 'movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=2, movieId=1073, new_ratings=3.1127612615922002, ratings=3.0),\n",
       " Row(userId=5, movieId=562, new_ratings=4.726646236437846, ratings=5.0),\n",
       " Row(userId=7, movieId=1288, new_ratings=3.3876945595817927, ratings=4.0),\n",
       " Row(userId=13, movieId=266, new_ratings=3.0448259327021043, ratings=3.0),\n",
       " Row(userId=13, movieId=1466, new_ratings=3.792032982260145, ratings=4.0),\n",
       " Row(userId=13, movieId=2866, new_ratings=2.9583415274420997, ratings=3.0),\n",
       " Row(userId=17, movieId=1918, new_ratings=4.170568373948343, ratings=4.0),\n",
       " Row(userId=23, movieId=296, new_ratings=3.1428828214821367, ratings=4.0),\n",
       " Row(userId=26, movieId=185, new_ratings=3.9912608329233716, ratings=4.0),\n",
       " Row(userId=30, movieId=637, new_ratings=3.8491857046397424, ratings=4.0),\n",
       " Row(userId=34, movieId=1089, new_ratings=2.9642579014484842, ratings=3.0),\n",
       " Row(userId=34, movieId=2089, new_ratings=3.817721423587683, ratings=3.0),\n",
       " Row(userId=34, movieId=2289, new_ratings=2.09083864188565, ratings=2.0),\n",
       " Row(userId=34, movieId=2889, new_ratings=2.773606266323415, ratings=2.0),\n",
       " Row(userId=34, movieId=3489, new_ratings=5.033721141973383, ratings=4.0),\n",
       " Row(userId=36, movieId=15, new_ratings=4.778165755192467, ratings=4.0),\n",
       " Row(userId=36, movieId=1015, new_ratings=4.2341070986474625, ratings=4.0),\n",
       " Row(userId=36, movieId=1615, new_ratings=3.042075568234389, ratings=3.0),\n",
       " Row(userId=36, movieId=6615, new_ratings=3.931801936708086, ratings=3.0),\n",
       " Row(userId=43, movieId=356, new_ratings=1.7984717242487762, ratings=3.0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of dataset\n",
    "new_ratings_byTime.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_ratings_byTime = new_ratings_byTime.drop(new_ratings_byTime[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_validation(validation):\n",
    "    return validation.map(lambda p: (p[0], p[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on training data\n",
    "\n",
    "def train_evaluate_als(train, validation, rank, iterations_num, lambda_val):\n",
    "    model = ALS.train(train, rank, iterations_num, lambda_val)\n",
    "    predictions = model.predictAll(prepare_validation(test)).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "    MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = [10, 20, 30, 40, 50]\n",
    "lambda_values = [0.01,0.1,1.0,10.0]\n",
    "ITERATIONS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_mse_results(rank, lambda_value, mse, rmse):\n",
    "    print(\"Rank=%d, Lambda=%0.2f, MSE=%s, RMSE=%s\" % (rank, lambda_value, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_parameters(train, validation, ranks, lambda_values):\n",
    "    for r in ranks:\n",
    "        for l in lambda_values:\n",
    "            mse= train_evaluate_als(new_ratings_byTime, validation, r, ITERATIONS, l)\n",
    "            report_mse_results(r, l, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1118, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 300, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/inspect.py\", line 497, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/inspect.py\", line 466, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/inspect.py\", line 451, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/Users/haiweisu/anaconda/lib/python2.7/genericpath.py\", line 26, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1829\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1830\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1392\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1300\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m             )\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/haiweisu/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "evaluate_parameters(new_ratings_byTime, ratings_validation, ranks, lambda_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
